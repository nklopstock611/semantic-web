{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrega 2 Proyecto - Semantic Web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8EJFyh8Ymis"
      },
      "source": [
        "## Definición Ontología\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkWTYvmYmit"
      },
      "source": [
        "En este archivo se define la ontología usada para el proyecto. A partir de los datos obtenidos en la entrega 1 se definen:\n",
        "- Tipos de datos\n",
        "- Clases y subclases\n",
        "- Propiedades y subpropiedades\n",
        "- Restricciones y características de las entidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWDt1pGOYmit"
      },
      "source": [
        "### Instalación dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J6AETqR5Ymiu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdflib in /usr/local/python/3.10.13/lib/python3.10/site-packages (7.0.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from rdflib) (0.6.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from rdflib) (3.1.2)\n",
            "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xc3wYzODYmiv"
      },
      "outputs": [],
      "source": [
        "from rdflib import Graph, Literal, RDF, URIRef, Namespace, BNode, XSD, Bag, Seq\n",
        "from rdflib.namespace import RDF, RDFS, OWL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp3LYaC5Ymiv"
      },
      "source": [
        "### Definición de espacio de nombres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rq59fDqFYmiv"
      },
      "outputs": [],
      "source": [
        "g = Graph()\n",
        "\n",
        "# Definición de los prefijos de los espacios de nombres\n",
        "g.bind('rdf', RDF)\n",
        "g.bind('rdfs', RDFS)\n",
        "g.bind('owl', OWL)\n",
        "g.bind(\"xsd\", XSD)\n",
        "\n",
        "# Definición de los prefijos de ontologías y recursos\n",
        "UEX = Namespace(\"http://www.uniandes.web.semantica.example.org/\")\n",
        "UEV = Namespace(\"http://www.uniandes.web.semantica.ejemplo.org/voca#\")\n",
        "g.bind('uex', UEX)\n",
        "g.bind('uev', UEV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lCqGyPGYmiv"
      },
      "source": [
        "### Definición de clases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYvodRqmYmiv"
      },
      "source": [
        "De la primera entrega se identificaron diferentes clases que hacen parte de la ontología de papers. En esta sección se definen estas clases usando la definición de tipo rdfs: Class. Las clases definidas son las siguientes:\n",
        "- Paper\n",
        "- Author\n",
        "- Referencia (Subclase Paper)\n",
        "\n",
        "Así mismo, se revisaron que atributos son comunmente definidos como clases en DBPedia, de lo cual definimos los siguientes atributos como Clases en preparación a la entrega 3:\n",
        "- Concept Annotation\n",
        "- Country\n",
        "- City\n",
        "- Meeting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDks8i9tYmiw",
        "outputId": "edcbe974-0aed-4ec0-f4f4-7cc9a29d819d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clases principales\n",
        "g.add((UEV.Paper, RDF.type, RDFS.Class))\n",
        "g.add((UEV.Author, RDF.type, RDFS.Class))\n",
        "g.add((UEV.Reference, RDF.type, RDFS.Class))\n",
        "\n",
        "# Clases para el futuro\n",
        "g.add((UEV.ConceptAnnotation, RDF.type, RDFS.Class))\n",
        "g.add((UEV.Country, RDF.type, RDFS.Class))\n",
        "g.add((UEV.City, RDF.type, RDFS.Class))\n",
        "g.add((UEV.Meeting, RDF.type, RDFS.Class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayImYhE0Ymiw"
      },
      "source": [
        "### Definición de Subclases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN0MTmuPYmiw"
      },
      "source": [
        "Se identifica que una referencia sigue siendo un paper pero es una subclase de paper, por lo que se define acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4xR_6JaYmiw",
        "outputId": "ba171fc5-2216-4e5a-f2fd-affb5169c2d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g.add((UEV.Reference, RDFS.subClassOf, UEV.Paper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1QUCfOoYmix"
      },
      "source": [
        "### Definición de Propiedades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY94uqZPYmix"
      },
      "source": [
        "De la primera entrega se identificaron diferentes propiedades que hacen parte de la ontología de papers. En esta sección se definen estas propiedades usando la definición de tipo rdfs: Property. Las propiedades definidas de atributos son las siguientes:\n",
        "- Paper\n",
        "  - Text\n",
        "    - Title (Sub)\n",
        "    - Abstract (Sub)\n",
        "    - Introduction (Sub)\n",
        "    - Conclusion (Sub)\n",
        "    - Concept_Anotation (Sub)\n",
        "  - Publication_Date\n",
        "  - Paper PDF\n",
        "- Author\n",
        "  - Forename\n",
        "  - Surname\n",
        "  - Email\n",
        "  - Afilliation\n",
        "  - Adress_Line\n",
        "  - Post_code\n",
        "  - Settlement\n",
        "  - Country\n",
        "- Referencia (Subclase Paper)\n",
        "  - Title\n",
        "  - Publication_Date\n",
        "  - Meeting\n",
        "  - City\n",
        "  - Country\n",
        "  - Note\n",
        "\n",
        "Así mismo, se identificaron las siguientes relaciones entre clases :\n",
        "- Un paper tiene autores\n",
        "- Un autor tiene papers\n",
        "- Un paper tiene referencias\n",
        "- Una referencia esta asociada a papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_EYvJQoYmix",
        "outputId": "7a3714f5-7b84-4929-94ef-333dd24f2f93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Valores de Paper\n",
        "g.add((UEV.Text, RDF.type, OWL.ObjectPropert))\n",
        "g.add((UEV.Title, RDF.type, OWL.ObjectPropert))\n",
        "g.add((UEV.Abstract, RDF.type, OWL.ObjectPropert))\n",
        "g.add((UEV.Introduction, RDF.type, OWL.ObjectPropert))\n",
        "g.add((UEV.Conclusion, RDF.type, OWL.ObjectPropert))\n",
        "g.add((UEV.Paper_pdf, RDF.type, OWL.ObjectPropert))\n",
        "\n",
        "g.add((UEV.hasConcept_Annotation, RDF.type, OWL.ObjectPropert)) # Clase futura\n",
        "g.add((UEV.Publication_Date, RDF.type, OWL.ObjectPropert))\n",
        "\n",
        "# Valores de Author\n",
        "g.add((UEV.Forename, RDF.type, RDF.Property))\n",
        "g.add((UEV.Surname, RDF.type, RDF.Property))\n",
        "g.add((UEV.Email, RDF.type, RDF.Property))\n",
        "g.add((UEV.Affiliation, RDF.type, RDF.Property))\n",
        "g.add((UEV.Address_Line, RDF.type, RDF.Property))\n",
        "g.add((UEV.Post_code, RDF.type, RDF.Property))\n",
        "g.add((UEV.Settlement, RDF.type, RDF.Property))\n",
        "g.add((UEV.hasCountry, RDF.type, RDF.Property)) # Clase futura\n",
        "\n",
        "# Valores especificos de referencias\n",
        "g.add((UEV.hasMeeting, RDF.type, RDF.Property)) # Clase futura\n",
        "g.add((UEV.hasCity, RDF.type, RDF.Property)) # Clase futura\n",
        "g.add((UEV.Note, RDF.type, RDF.Property))\n",
        "\n",
        "# Relaciones\n",
        "g.add((UEV.isAuthorOf, RDF.type, RDF.Property))\n",
        "g.add((UEV.hasReference, RDF.type, RDF.Property))\n",
        "\n",
        "g.add((UEV.hasAuthor, OWL.inverseOf, UEV.isAuthorOf))\n",
        "g.add((UEV.isReferencedBy, OWL.inverseOf, UEV.hasReference))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYUSoVuYYmix"
      },
      "source": [
        "### Definición de Subpropiedades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVwr9YLvYmix"
      },
      "source": [
        "Se identifica que existen propiedades que hace referencia a texto de los papers, por lo que Title, Abstract y Concept_Anotation se pueden considerar subpropiedades de Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H8Ayn6ZYmix",
        "outputId": "f9a18257-0673-4eaf-cf67-49f38e51a936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g.add((UEV.Title, RDFS.subPropertyOf, UEV.Text))\n",
        "g.add((UEV.Abstract, RDFS.subPropertyOf, UEV.Text))\n",
        "g.add((UEV.Concept_Annotation, RDFS.subPropertyOf, UEV.Text))\n",
        "g.add((UEV.Introduction, RDFS.subPropertyOf, UEV.Text))\n",
        "g.add((UEV.Conclusion, RDFS.subPropertyOf, UEV.Text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gfo1n60Ymix"
      },
      "source": [
        "### Definición de Dominio y Rango"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZtYqbOjYmiy"
      },
      "source": [
        "En esta sección se definieron los dominios y rangos para las propiedades definidas anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eo2xS42Ymiy",
        "outputId": "9538c065-109d-4034-8493-60213a9a7107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Texto\n",
        "g.add((UEV.Text, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Text, RDFS.range, XSD.string))\n",
        "# Title\n",
        "g.add((UEV.Title, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Title, RDFS.range, XSD.string))\n",
        "# Abstract\n",
        "g.add((UEV.Abstract, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Abstract, RDFS.range, XSD.string))\n",
        "# Introduction\n",
        "g.add((UEV.Introduction, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Introduction, RDFS.range, XSD.string))\n",
        "# Conclusion\n",
        "g.add((UEV.Conclusion, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Conclusion, RDFS.range, XSD.string))\n",
        "# Concept_Anotation\n",
        "g.add((UEV.hasConcept_Annotation, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.hasConcept_Annotation, RDFS.range, UEV.ConceptAnnotation))\n",
        "\n",
        "# Paper_pdf\n",
        "g.add((UEV.Paper_pdf, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Paper_pdf, RDFS.range, XSD.string))\n",
        "\n",
        "# Publication_Date (Puede tener año, año-mes o año-mes-día) -- Revisar si es posible estandarizar formato y pasar a date\n",
        "g.add((UEV.Publication_Date, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.Publication_Date, RDFS.range, XSD.string))\n",
        "\n",
        "# Forename\n",
        "g.add((UEV.Forename, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Forename, RDFS.range, XSD.string))\n",
        "# Surname\n",
        "g.add((UEV.Surname, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Surname, RDFS.range, XSD.string))\n",
        "# Email\n",
        "g.add((UEV.Email, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Email, RDFS.range, XSD.string))\n",
        "# Affiliation\n",
        "g.add((UEV.Affiliation, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Affiliation, RDFS.range, XSD.string))\n",
        "# Address_Line\n",
        "g.add((UEV.Address_Line, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Address_Line, RDFS.range, XSD.string))\n",
        "# Post_code -- Puede ser numero\n",
        "g.add((UEV.Post_code, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Post_code, RDFS.range, XSD.string))\n",
        "# Settlement\n",
        "g.add((UEV.Settlement, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.Settlement, RDFS.range, XSD.string))\n",
        "# Country -- Pensar modelarlo como clase\n",
        "g.add((UEV.hasCountry, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.hasCountry, RDFS.range, UEV.Country))\n",
        "# Meeting\n",
        "g.add((UEV.hasMeeting, RDFS.domain, UEV.Reference))\n",
        "g.add((UEV.hasMeeting, RDFS.range, UEV.Meeting))\n",
        "# City -- Pensar modelarlo como clase\n",
        "g.add((UEV.hasCity, RDFS.domain, UEV.Reference))\n",
        "g.add((UEV.hasCity, RDFS.range, UEV.City))\n",
        "# Note\n",
        "g.add((UEV.Note, RDFS.domain, UEV.Reference))\n",
        "g.add((UEV.Note, RDFS.range, XSD.string))\n",
        "\n",
        "# Relaciones\n",
        "# g.add((UEV.hasAuthor, RDFS.domain, UEV.Paper))\n",
        "# g.add((UEV.hasAuthor, RDFS.range, UEV.Author))\n",
        "\n",
        "g.add((UEV.hasReference, RDFS.domain, UEV.Paper))\n",
        "g.add((UEV.hasReference, RDFS.range, UEV.Reference))\n",
        "\n",
        "g.add((UEV.isAuthorOf, RDFS.domain, UEV.Author))\n",
        "g.add((UEV.isAuthorOf, RDFS.range, UEV.Paper))\n",
        "\n",
        "# g.add((UEV.isReferencedBy, RDFS.domain, UEV.Reference))\n",
        "# g.add((UEV.isReferencedBy, RDFS.range, UEV.Paper))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l4QYH8tYmiy"
      },
      "source": [
        "### Definición Restricciones y Caracteristicas Ontología"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSVVKKNqYmiy"
      },
      "source": [
        "En esta sección se definen las restricciones y caracteristicas para las clases y propiedades, por lo que se dividira en estas dos secciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGuRj8K9Ymiy",
        "outputId": "f4570af3-0de9-47f0-c12d-54252d50fc9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N30773b1c752348e79413803435f0796b (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Clases Disjuntas\n",
        "g.add((UEV.Paper, OWL.disjointWith, UEV.Author))\n",
        "\n",
        "# Restricciones Texto Functional Property\n",
        "properties = {\n",
        "    UEV.Title: \"Título del paper\",\n",
        "    UEV.Abstract: \"Abstract del paper\",\n",
        "    UEV.Publication_Date: \"Fecha de publicación del paper\",\n",
        "    UEV.Paper_pdf: \"Referencia al PDF del paper\"\n",
        "}\n",
        "\n",
        "for prop, description in properties.items():\n",
        "    g.add((prop, RDF.type, OWL.FunctionalProperty))\n",
        "    g.add((prop, RDF.type, RDF.Property))\n",
        "\n",
        "# Restricción cardinalidad relación paper <-> autor\n",
        "restriction = BNode()\n",
        "\n",
        "g.add((restriction, RDF.type, OWL.Restriction))\n",
        "g.add((restriction, OWL.onProperty, UEV.hasAuthor))\n",
        "g.add((restriction, OWL.minCardinality, Literal(1)))\n",
        "\n",
        "g.add((UEV.Paper, RDFS.subClassOf, restriction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br9aDXycYmiy"
      },
      "source": [
        "### Inferencia de tuplas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDt-IZPCYmiy",
        "outputId": "93b3c9c4-8122-4e7f-9ea1-30cdd0185d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: owlrl in /usr/local/python/3.10.13/lib/python3.10/site-packages (6.0.2)\n",
            "Requirement already satisfied: rdflib>=6.0.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from owlrl) (7.0.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from rdflib>=6.0.2->owlrl) (0.6.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from rdflib>=6.0.2->owlrl) (3.1.2)\n",
            "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.0.2->owlrl) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install owlrl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oZHwaPlNYmiy"
      },
      "outputs": [],
      "source": [
        "import owlrl\n",
        "\n",
        "owl_reasoner = owlrl.CombinedClosure.RDFS_OWLRL_Semantics(g, False, False, False)\n",
        "owl_reasoner.closure()\n",
        "owl_reasoner.flush_stored_triples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzL0SNehYmiz"
      },
      "source": [
        "### Exportación ontología"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cfHdThgxYmiz"
      },
      "outputs": [],
      "source": [
        "with open(\"semantic_ontology_model.rdf\", \"w\") as f:\n",
        "    f.write(g.serialize(format='xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFflhcGgYmiz"
      },
      "outputs": [],
      "source": [
        "print(g.serialize(format='n3'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOewQ6gpYmiz"
      },
      "source": [
        "## Definición Instancias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b2s-EtRYmiz"
      },
      "source": [
        "Las instancias en este caso se definen a partir del desarrollo en la entrega 1, por lo que se pasan los datos desde un JSON a la ontología"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8icmBqKiYmiz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from rdflib import Graph, Literal, RDF, URIRef, Namespace, BNode, XSD, Bag, Seq\n",
        "from rdflib.namespace import RDF, RDFS, OWL\n",
        "\n",
        "g = Graph()\n",
        "\n",
        "# Definición de los prefijos de los espacios de nombres\n",
        "g.bind('rdf', RDF)\n",
        "g.bind('rdfs', RDFS)\n",
        "g.bind('owl', OWL)\n",
        "g.bind(\"xsd\", XSD)\n",
        "\n",
        "# Definición de los prefijos de ontologías y recursos\n",
        "UEX = Namespace(\"http://www.uniandes.web.semantica.example.org/\")\n",
        "UEV = Namespace(\"http://www.uniandes.web.semantica.ejemplo.org/voca#\")\n",
        "g.bind('uex', UEX)\n",
        "g.bind('uev', UEV)\n",
        "\n",
        "archivo_json = '/semantic-web/second-task/metadata_keywords_2.json'\n",
        "\n",
        "# Abrimos el archivo JSON para leer los datos\n",
        "with open(archivo_json, 'r', encoding='utf-8') as archivo:\n",
        "    datos = json.load(archivo)\n",
        "\n",
        "# Función para verificar si una instancia ya existe en la ontología\n",
        "def instance_exists(graph, instance_uri):\n",
        "    return (instance_uri, None, None) in graph\n",
        "\n",
        "# Iteramos sobre cada paper usando su ID único\n",
        "for paper_id, paper_content in datos.items():\n",
        "\n",
        "    # El titulo es lo que se carga como clase en la ontología\n",
        "    paper_class = paper_content.get('paper_title', '') # Crear un URI para el paper usando el ID del paper\n",
        "    if paper_class != '' and paper_class is not None:\n",
        "        # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "        paper_class = paper_class.lower().replace(' ', '_')\n",
        "        # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "        paper_class = paper_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "        paper_uri = UEX[paper_class]\n",
        "        paper_exists = instance_exists(g, paper_uri)\n",
        "\n",
        "        # Si el paper no existe, lo agregamos a la ontología\n",
        "        if not paper_exists:\n",
        "            g.add((paper_uri, RDF.type, UEV.Paper))\n",
        "\n",
        "            # Agrega los valores de las propiedades del paper a la ontología\n",
        "            # Con tal de que no sean vacíos o '' (en cuyo caso no se agregan)\n",
        "            if paper_content.get('paper_title', '') != '':\n",
        "                 g.add((paper_uri, UEV.Title, Literal(paper_content.get('paper_title', ''))))\n",
        "            if paper_content.get('paper_abstract', '') != '':\n",
        "                g.add((paper_uri, UEV.Abstract, Literal(paper_content.get('paper_abstract', ''))))\n",
        "            if paper_content.get('paper_introduction', '') != '':\n",
        "                g.add((paper_uri, UEV.Introduction, Literal(paper_content.get('paper_introduction', ''))))\n",
        "            if paper_content.get('paper_conclusion', '') != '':\n",
        "                g.add((paper_uri, UEV.Conclusion, Literal(paper_content.get('paper_conclusion', ''))))\n",
        "            if paper_content.get('paper_publication_year', '') != '' and paper_content.get('paper_publication_year', '') is not None:\n",
        "                g.add((paper_uri, UEV.Publication_Date, Literal(paper_content.get('paper_publication_year', ''), datatype=XSD.string)))\n",
        "            if paper_content.get('paper_downloaded_pdf', '') != '':\n",
        "                g.add((paper_uri, UEV.Paper_pdf, Literal(paper_content.get('paper_downloaded_pdf', ''))))\n",
        "\n",
        "        # Iteramos sobre cada keyword del paper\n",
        "        for keyword in paper_content.get('paper_key_words', [])['entities']:\n",
        "            keyword_class = keyword.lower().replace(' ', '_')\n",
        "            # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "            keyword_class = keyword_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "            keyword_uri = UEX[keyword_class]\n",
        "            keyword_exists = instance_exists(g, keyword_uri)\n",
        "\n",
        "            # Si la keyword no existe, la agregamos a la ontología\n",
        "            if not keyword_exists:\n",
        "                g.add((keyword_uri, RDF.type, UEV.ConceptAnnotation))\n",
        "\n",
        "            # Relacionamos el paper con la keyword\n",
        "            g.add((paper_uri, UEV.hasConcept_Annotation, keyword_uri))\n",
        "\n",
        "        # Iteramos sobre cada autor del paper\n",
        "        for author in paper_content.get('paper_authors', []):\n",
        "            author_class = author.get('paper_authors_forename', '') + ' ' + author.get('paper_authors_surname', '')\n",
        "            if author_class != ' ' and author_class is not None:\n",
        "                # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                author_class = author_class.lower().replace(' ', '_')\n",
        "                # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                author_class = author_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                author_uri = UEX[author_class]\n",
        "                author_exists = instance_exists(g, author_uri)\n",
        "\n",
        "                # Si el autor no existe, lo agregamos a la ontología\n",
        "                if not author_exists:\n",
        "                    g.add((author_uri, RDF.type, UEV.Author))\n",
        "\n",
        "                    # Agrega los valores de las propiedades del autor a la ontología\n",
        "                    # Con tal de que no sean vacíos o '' (en cuyo caso no se agregan)\n",
        "                    if author.get('paper_author_forename', '') != '':\n",
        "                        g.add((author_uri, UEV.Forename, Literal(author.get('paper_authors_forename', ''))))\n",
        "                    if author.get('paper_author_surname', '') != '':\n",
        "                        g.add((author_uri, UEV.Surname, Literal(author.get('paper_authors_surname', ''))))\n",
        "                    if author.get('paper_author_email', '') != '':\n",
        "                        g.add((author_uri, UEV.Email, Literal(author.get('paper_authors_email', ''))))\n",
        "                    if author.get('paper_author_affiliation', '') != '':\n",
        "                        g.add((author_uri, UEV.Affiliation, Literal(author.get('paper_authors_affiliation', ''))))\n",
        "                    if author.get('paper_author_address_line', '') != '':\n",
        "                        g.add((author_uri, UEV.Address_Line, Literal(author.get('paper_authors_address_line', ''))))\n",
        "                    if author.get('paper_author_post_code', '') != '':\n",
        "                        g.add((author_uri, UEV.Post_code, Literal(author.get('paper_authors_post_code', ''))))\n",
        "                    if author.get('paper_author_settlement', '') != '':\n",
        "                        g.add((author_uri, UEV.Settlement, Literal(author.get('paper_authors_settlement', ''))))\n",
        "                    if author.get('paper_author_country', '') != '' and author.get('paper_authors_country', '') is not None:\n",
        "                        #pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                        author_country = author.get('paper_authors_country', '').lower().replace(' ', '_')\n",
        "                        # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                        author_country = author_country.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                        # Se crea un URI para el país del autor\n",
        "                        country_uri = UEX[author_country]\n",
        "\n",
        "                        # Si el país no existe, lo agregamos a la ontología\n",
        "                        if not instance_exists(g, country_uri):\n",
        "                            g.add((country_uri, RDF.type, UEV.Country))\n",
        "\n",
        "                        # Revisa que la propiedad con esos valores no exista ya\n",
        "                        if not (author_uri, UEV.hasCountry, country_uri) in g:\n",
        "                            g.add((author_uri, UEV.hasCountry, country_uri))\n",
        "\n",
        "                # Relacionamos el autor con el paper\n",
        "                g.add((author_uri, UEV.isAuthorOf, paper_uri))\n",
        "\n",
        "        # Iteramos sobre cada referencia del paper\n",
        "        for reference in paper_content.get('paper_references', []):\n",
        "          reference_class = reference.get('reference_paper_title', '')\n",
        "          # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "          reference_class = reference_class.lower().replace(' ', '_')\n",
        "          # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "          reference_class = reference_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "          # Revisa que la referencia no tenga el mismo nombre que el paper\n",
        "          if reference_class != paper_class and reference_class != '' and reference_class is not None:\n",
        "              reference_uri = UEX[reference_class]\n",
        "              reference_exists = instance_exists(g, reference_uri)\n",
        "\n",
        "              # Si la referencia no existe, la agregamos a la ontología\n",
        "              if not reference_exists:\n",
        "                  g.add((reference_uri, RDF.type, UEV.Reference))\n",
        "\n",
        "                  # Agrega los valores de las propiedades de la referencia a la ontología\n",
        "                  # Con tal de que no sean vacíos o '' (en cuyo caso no se agregan)\n",
        "                  if reference.get('reference_paper_title', '') != '':\n",
        "                      g.add((reference_uri, UEV.Title, Literal(reference.get('reference_paper_title', ''))))\n",
        "                  if reference.get('reference_paper_publication_date', '') != '':\n",
        "                      g.add((reference_uri, UEV.Publication_Date, Literal(reference.get('reference_paper_publication_date', ''), datatype=XSD.string)))\n",
        "                  if reference.get('reference_paper_meeting', '') != '' and reference.get('reference_paper_meeting', '') is not None:\n",
        "                      # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                      meeting_class = reference.get('reference_paper_meeting', '').lower().replace(' ', '_')\n",
        "                      # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                      meeting_class = meeting_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                      # Se crea un URI para la conferencia de la referencia\n",
        "                      meeting_uri = UEX[meeting_class]\n",
        "\n",
        "                      # Si la conferencia no existe, la agregamos a la ontología\n",
        "                      if not instance_exists(g, meeting_uri):\n",
        "                          g.add((meeting_uri, RDF.type, UEV.Meeting))\n",
        "\n",
        "                      g.add((reference_uri, UEV.hasMeeting, meeting_uri))\n",
        "\n",
        "                  if reference.get('reference_paper_city', '') != '' and reference.get('reference_paper_city', '') is not None:\n",
        "                      # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                      city_class = reference.get('reference_paper_city', '').lower().replace(' ', '_')\n",
        "                      # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                      city_class = city_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                      # Se crea un URI para la ciudad de la referencia\n",
        "                      city_uri = UEX[city_class]\n",
        "\n",
        "                      # Si la ciudad no existe, la agregamos a la ontología\n",
        "                      if not instance_exists(g, city_uri):\n",
        "                          g.add((city_uri, RDF.type, UEV.City))\n",
        "\n",
        "                      g.add((reference_uri, UEV.hasCity, city_uri))\n",
        "\n",
        "                  if reference.get('reference_paper_country', '') != '' and reference.get('reference_paper_country', '') is not None:\n",
        "                      # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                      country_class = reference.get('reference_paper_country', '').lower().replace(' ', '_')\n",
        "                      # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                      country_class = country_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                      # Se crea un URI para el país de la referencia\n",
        "                      country_uri = UEX[country_class]\n",
        "\n",
        "                      # Si el país no existe, lo agregamos a la ontología\n",
        "                      if not instance_exists(g, country_uri):\n",
        "                          g.add((country_uri, RDF.type, UEV.Country))\n",
        "\n",
        "                      g.add((reference_uri, UEV.hasCountry, country_uri))\n",
        "\n",
        "                  #if reference.get('reference_paper_note', '') != '':\n",
        "                  #    g.add((reference_uri, UEV.Note, Literal(reference.get('reference_paper_note', ''))))\n",
        "\n",
        "              # Relacionamos el paper con la referencia\n",
        "              g.add((paper_uri, UEV.hasReference, reference_uri))\n",
        "\n",
        "\n",
        "              # Iteramos sobre los autores de las referencias\n",
        "              for ref_author in reference.get('reference_paper_authors', []):\n",
        "                  ref_author_class = ref_author.get('reference_paper_author_forename', '') + ' ' + ref_author.get('reference_paper_author_surname', '')\n",
        "                  if ref_author_class != ' ' and ref_author_class is not None:\n",
        "                      # pasar a minúsculas y reemplazar espacios por guiones bajos\n",
        "                      ref_author_class = ref_author_class.lower().replace(' ', '_')\n",
        "                      # Elimina caracteres ?,\\,\" y ' de la clase\n",
        "                      ref_author_class = ref_author_class.replace('?', '').replace(',', '').replace('\"', '').replace(\"'\", '')\n",
        "                      ref_author_uri = UEX[ref_author_class]\n",
        "                      ref_author_exists = instance_exists(g, ref_author_uri)\n",
        "\n",
        "                      # Si el autor de la referencia no existe, lo agregamos a la ontología\n",
        "                      if not ref_author_exists:\n",
        "                          g.add((ref_author_uri, RDF.type, UEV.Author))\n",
        "\n",
        "                          # Agrega los valores de las propiedades del autor de la referencia a la ontología\n",
        "                          # Con tal de que no sean vacíos o '' (en cuyo caso no se agregan)\n",
        "                          if ref_author.get('reference_paper_author_forename', '') != '':\n",
        "                              g.add((ref_author_uri, UEV.Forename, Literal(ref_author.get('reference_paper_author_forename', ''))))\n",
        "                          if ref_author.get('reference_paper_author_surname', '') != '':\n",
        "                              g.add((ref_author_uri, UEV.Surname, Literal(ref_author.get('reference_paper_author_surname', ''))))\n",
        "\n",
        "                      # Relacionamos la referencia con el autor hasAuthor\n",
        "                      g.add((ref_author_uri, UEV.isAuthorOf, reference_uri))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpZhrLvYmi0"
      },
      "source": [
        "### Inferencia de Tuplas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KYeV8FWrYmi0"
      },
      "outputs": [],
      "source": [
        "import owlrl\n",
        "\n",
        "owl_reasoner = owlrl.CombinedClosure.RDFS_OWLRL_Semantics(g, False, False, False)\n",
        "owl_reasoner.closure()\n",
        "owl_reasoner.flush_stored_triples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTkAkzsRYmi0"
      },
      "source": [
        "### Serialización Instancias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LV7ZU2kiYmi0"
      },
      "outputs": [],
      "source": [
        "with open(\"semantic_instances.rdf\", \"w\") as f:\n",
        "    f.write(g.serialize(format='xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xuaE3UXkYmi2",
        "outputId": "d32df3e6-fa25-4784-f4c0-e24814190191"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-58bc9dec9456>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, destination, format, base, encoding, **args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m                 \u001b[0mserializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, stream, base, encoding, spacious, **args)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spacious\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacious\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0msubjects_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderSubjects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessTriple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessTriple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/n3.py\u001b[0m in \u001b[0;36mpreprocessTriple\u001b[0;34m(self, triple)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessTriple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN3Serializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessTriple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\u001b[0m in \u001b[0;36mpreprocessTriple\u001b[0;34m(self, triple)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# Don't use generated prefixes for subjects and objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVERB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_GEN_QNAME_FOR_DT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/n3.py\u001b[0m in \u001b[0;36mgetQName\u001b[0;34m(self, uri, gen_prefix)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mqname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mqname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mqname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN3Serializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/serializers/turtle.py\u001b[0m in \u001b[0;36mgetQName\u001b[0;34m(self, uri, gen_prefix)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_qname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# is the uri a namespace in itself?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mcompute_qname\u001b[0;34m(self, uri, generate)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_qname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURIRef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_qname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     def bind(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(g.serialize(format='n3'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n1RhbMWwXnN"
      },
      "source": [
        "## Consultas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opppP00q79wT"
      },
      "source": [
        "### SPARQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ4T0Lp5waMq",
        "outputId": "4a1f3466-ace3-44ae-8b91-26744c72f9b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: rdflib>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from SPARQLWrapper) (7.0.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n",
            "Installing collected packages: SPARQLWrapper\n",
            "Successfully installed SPARQLWrapper-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1qx5OQ8EwcQq"
      },
      "outputs": [],
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8BPocrqzAo3"
      },
      "outputs": [],
      "source": [
        "g.parse(\"semantic_ontology_model.rdf\")\n",
        "g.parse(\"semantic_instances.rdf\") # este parseo va a tardar más o menos 4 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEch8X1jweOf",
        "outputId": "9952d26c-294e-43c7-a4c4-b09393cdd429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.uniandes.web.semantica.example.org/constant_time_distributed_dominating_set_approximation\n",
            "http://www.uniandes.web.semantica.example.org/authenticated_data_structures_for_graph_and_geometric_searching\n",
            "http://www.uniandes.web.semantica.example.org/the_complexity_of_computing_a_nash_equilibrium\n",
            "http://www.uniandes.web.semantica.example.org/expander_graphs_and_their_applications\n",
            "http://www.uniandes.web.semantica.example.org/subgraph_sparsification_and_nearly_optimal_ultrasparsifiers__\n",
            "http://www.uniandes.web.semantica.example.org/unifying_evolutionary_dynamics\n",
            "http://www.uniandes.web.semantica.example.org/modeling_of_the_ultrasonic_sonic_driller_corer__usdc\n",
            "http://www.uniandes.web.semantica.example.org/stateful_bulk_processing_for_incremental_analytics\n",
            "http://www.uniandes.web.semantica.example.org/a_moderately_exponential_time_algorithm_for_full_degree_spanning_tree\n",
            "http://www.uniandes.web.semantica.example.org/average_case_analysis_of_dynamic_graph_algorithms\n"
          ]
        }
      ],
      "source": [
        "# Papers relacionados con el keyword \"graph_theory\".\n",
        "\n",
        "qres = g.query(\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    PREFIX dbr: <http://dbpedia.org/resource/>\n",
        "    PREFIX uex: <http://www.uniandes.web.semantica.example.org/>\n",
        "    PREFIX uev: <http://www.uniandes.web.semantica.ejemplo.org/voca#>\n",
        "\n",
        "    SELECT ?paper\n",
        "    WHERE {\n",
        "        ?paper a uev:Paper .\n",
        "        ?paper uev:hasConcept_Annotation uex:graph_theory .\n",
        "    } limit 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for row in qres:\n",
        "  print(row.paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX6F775U03X3",
        "outputId": "2b3a2c81-cd45-49cd-a368-48388bf6eaac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.uniandes.web.semantica.example.org/the_webgraph_framework_i__compression_techniques\n",
            "http://www.uniandes.web.semantica.example.org/optimizing_data_parallel_operations_on_many_core_platforms\n"
          ]
        }
      ],
      "source": [
        "# Papers publicados en la ciudad \"manhattan\".\n",
        "\n",
        "qres = g.query(\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    PREFIX dbr: <http://dbpedia.org/resource/>\n",
        "    PREFIX uex: <http://www.uniandes.web.semantica.example.org/>\n",
        "    PREFIX uev: <http://www.uniandes.web.semantica.ejemplo.org/voca#>\n",
        "\n",
        "    SELECT ?paper\n",
        "    WHERE {\n",
        "        ?paper rdf:type ?class .\n",
        "        ?paper uev:hasCity uex:manhattan .\n",
        "        FILTER (?class IN (uev:Paper, uev:Reference))\n",
        "    } LIMIT 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for row in qres:\n",
        "  print(row.paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ5EAoeD3ikt",
        "outputId": "6c6a25f4-f15e-4ce4-b141-796b89a51f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PAPER: http://www.uniandes.web.semantica.example.org/information_systems_frontiers__isf___special_issue_on_enterprise_services_computing__evolution_and_challenges \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/service_oriented_middleware_for_managing_interenterprise_collaborations \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/trust_management_survey \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/making_multi_dimensional_trust_decisions_on_inter_enterprise_collaborations \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/reputation_management_survey \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/guarding_enterprise_collaborations_with_trust_decisions_the_tube_approach \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/s_ruohomaa \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/automated_management_of_interorganisational_applications \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/l_kutvonen \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/building_b2b_middleware__interoperability_knowledge_management_issues \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/l_kutvonen \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/information_systems_frontiers__isf___special_issue_on_enterprise_services_computing__evolution_and_challenges \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/l_kutvonen \n",
            "\n",
            "PAPER: http://www.uniandes.web.semantica.example.org/inter_enterprise_collaboration_management_in_dynamic_business_networks \n",
            "AUTHOR: http://www.uniandes.web.semantica.example.org/l_kutvonen \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Papers publicados por los autores del paper \"Trust management survey\".\n",
        "\n",
        "qres = g.query(\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    PREFIX dbr: <http://dbpedia.org/resource/>\n",
        "    PREFIX uex: <http://www.uniandes.web.semantica.example.org/>\n",
        "    PREFIX uev: <http://www.uniandes.web.semantica.ejemplo.org/voca#>\n",
        "\n",
        "  SELECT ?paper ?author\n",
        "  WHERE {\n",
        "      ?author uev:isAuthorOf uex:trust_management_survey .\n",
        "      ?author uev:isAuthorOf ?paper .\n",
        "      ?paper rdf:type ?class .\n",
        "      FILTER (?class IN (uev:Paper, uev:Reference))\n",
        "  }\n",
        "  LIMIT 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for row in qres:\n",
        "  print('PAPER:', row.paper, '\\nAUTHOR:', row.author, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D8cX2cE4YAE",
        "outputId": "e94cd701-a5bb-4ff4-9559-bedcbe320ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.uniandes.web.semantica.example.org/a_mathematical_theory_of_communication\n",
            "http://www.uniandes.web.semantica.example.org/on_the_relationship_between_autobiographical_memory_and_perceptual_learning\n",
            "http://www.uniandes.web.semantica.example.org/confirmation__disconfirmation__and_information_in_hypothesis_testing\n",
            "http://www.uniandes.web.semantica.example.org/the_structure_of_scientific_revolutions\n",
            "http://www.uniandes.web.semantica.example.org/the_logic_of_scientific_discovery\n",
            "http://www.uniandes.web.semantica.example.org/the_society_of_mind\n",
            "http://www.uniandes.web.semantica.example.org/adaptation_in_natural_and_artificial_systems\n",
            "http://www.uniandes.web.semantica.example.org/the_sciences_of_the_artificial\n",
            "http://www.uniandes.web.semantica.example.org/human_problem_solving\n",
            "http://www.uniandes.web.semantica.example.org/the_fractal_geometry_of_nature\n"
          ]
        }
      ],
      "source": [
        "# Papers referenciados por el paper \"The Two Great Stochastic Systems\".\n",
        "\n",
        "qres = g.query(\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    PREFIX dbr: <http://dbpedia.org/resource/>\n",
        "    PREFIX uex: <http://www.uniandes.web.semantica.example.org/>\n",
        "    PREFIX uev: <http://www.uniandes.web.semantica.ejemplo.org/voca#>\n",
        "\n",
        "    SELECT ?reference\n",
        "    WHERE {\n",
        "        ?reference a uev:Reference .\n",
        "        uex:the__two_great_stochastic_systems_ uev:hasReference ?reference .\n",
        "    } limit 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for row in qres:\n",
        "  print(row.reference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL50CoLo5yAh",
        "outputId": "b2339770-a623-440a-a120-91e71493ea6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.uniandes.web.semantica.example.org/optimal_selection_of_speech_data_for_automatic_speech_recognition_systems\n",
            "http://www.uniandes.web.semantica.example.org/perception_of_haptic_force_magnitude_during_hand_movements\n",
            "http://www.uniandes.web.semantica.example.org/constant_time_distributed_dominating_set_approximation\n",
            "http://www.uniandes.web.semantica.example.org/3d_deformable_face_tracking_with_a_commodity_depth_camera\n",
            "http://www.uniandes.web.semantica.example.org/on_local_reasoning_in_verification\n",
            "http://www.uniandes.web.semantica.example.org/retraction_note__multimedia_data_stream_information_mining_algorithm_based_on_jointed_neural_network_and_soft_clustering\n",
            "http://www.uniandes.web.semantica.example.org/characterizations_of_optimal_scalings_of_matrices\n",
            "http://www.uniandes.web.semantica.example.org/evaluating_window_joins_over_unbounded_streams\n",
            "http://www.uniandes.web.semantica.example.org/perpetual_environmentally_powered_sensor_networks\n",
            "http://www.uniandes.web.semantica.example.org/owl_datatypes__design_and_implementation\n"
          ]
        }
      ],
      "source": [
        "# Papers publicados en el meeting \"Heidelberg\".\n",
        "\n",
        "qres = g.query(\n",
        "    \"\"\"\n",
        "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
        "    PREFIX dbr: <http://dbpedia.org/resource/>\n",
        "    PREFIX uex: <http://www.uniandes.web.semantica.example.org/>\n",
        "    PREFIX uev: <http://www.uniandes.web.semantica.ejemplo.org/voca#>\n",
        "\n",
        "    SELECT ?paper\n",
        "    WHERE {\n",
        "        ?paper rdf:type ?class .\n",
        "        ?author uev:hasMeeting uex:heidelberg .\n",
        "        FILTER (?class IN (uev:Paper, uev:Reference))\n",
        "    } limit 10\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "for row in qres:\n",
        "  print(row.paper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPyXKJjs7_-6"
      },
      "source": [
        "### CYPHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3s8oKOH8CV9"
      },
      "outputs": [],
      "source": [
        "# Papers relacionados con el keyword \"graph_theory\".\n",
        "\n",
        "# MATCH (p:ns0__Paper)-[:ns0__hasConcept_Annotation]->(c:ns0__ConceptAnnotation {uri: \"http://www.uniandes.web.semantica.example.org/graph_theory\"}) RETURN p.uri LIMIT 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlFNc-HZ8MHl"
      },
      "outputs": [],
      "source": [
        "# Papers publicados en la ciudad \"manhattan\".\n",
        "\n",
        "# MATCH (p)-[:ns0__hasCity]->(:ns0__City {uri: \"http://www.uniandes.web.semantica.example.org/manhattan\"}) WHERE p:ns0__Paper OR p:ns0__Reference RETURN p.uri LIMIT 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvEUybP78_PZ"
      },
      "outputs": [],
      "source": [
        "# Papers publicados por el/la autor/a del paper \"Trust management survey\".\n",
        "\n",
        "# MATCH (a:ns0__Author)-[:ns0__isAuthorOf]->({uri: \"http://www.uniandes.web.semantica.example.org/trust_management_survey\"})\n",
        "# MATCH (a)-[:ns0__isAuthorOf]->(p)\n",
        "# WHERE p:ns0__Paper OR p:ns0__Reference\n",
        "# RETURN p.uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSRbAaIu_ocd"
      },
      "outputs": [],
      "source": [
        "# Papers referenciados por el paper \"The Two Great Stochastic Systems\".\n",
        "\n",
        "# MATCH (:ns0__Paper {uri: \"http://www.uniandes.web.semantica.example.org/the__two_great_stochastic_systems_\"})-[:ns0__hasReference]->(r:ns0__Reference) RETURN r.uri LIMIT 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFz66WvUAZwO"
      },
      "outputs": [],
      "source": [
        "# Papers publicados en el meeting \"Heidelberg\".\n",
        "\n",
        "# MATCH (p)-[:ns0__hasMeeting]->(:ns0__Meeting {uri: \"http://www.uniandes.web.semantica.example.org/heidelberg\"}) WHERE p:ns0__Paper OR p:ns0__Reference RETURN p.uri LIMIT 10"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
